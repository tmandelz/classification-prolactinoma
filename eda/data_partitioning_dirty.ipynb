{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning - Additional Dirty Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "random_state = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Data Partitioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned data\n",
    "df = pd.read_csv(r'../raw_data/label_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split Strategy\n",
    "We will Split the Data into a Train- and Testset. \n",
    "We are splitting each patient fully into either the train or the test set to avoid data leakage.\n",
    "This is ensured by checking for Patient ID duplicates (assert statement beneath) in the Dataframe. If each row only corresponds to one patient we can savely split the dataframe.\n",
    "\n",
    "\n",
    "Also we are gonna stratify the split on the binary labels to ensure that the train- and testset include about the same of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop patients without a label\n",
    "df= df[~df[\"Category\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient ID Duplicate Check\n",
    "assert len(df[df[\"Patient_ID\"].duplicated()]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary fields\n",
    "df=df[['Patient_ID','Category']]\n",
    "# split columns into features and labels\n",
    "X = df.drop(columns=[\"Category\"])\n",
    "y = df[\"Category\"]\n",
    "# stratified train/test split on labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=random_state)\n",
    "print(\"Total Patients Train set:\", len(X_train))\n",
    "print(\"Total Patients Test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_diff = ((y_train.value_counts(normalize=True) - y_test.value_counts(normalize=True)) *100).iloc[1]\n",
    "print(f\"Label Distribution relative Difference between Train- and Testset:\\n\",\"±\",np.round(np.abs(label_diff),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for training and test data\n",
    "train_data = pd.DataFrame(X_train)\n",
    "train_data['Category'] = y_train\n",
    "\n",
    "test_data = pd.DataFrame(X_test)\n",
    "test_data['Category'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole lab dataset with all cases and merge them with the patient data\n",
    "df_more_data = pd.read_csv(r'../raw_data/data_dirty_merge.csv')\n",
    "train_data_merged = train_data.merge(df_more_data,how='inner',on=['Patient_ID','Category'])\n",
    "test_data_merged = test_data.merge(df_more_data,how='inner',on=['Patient_ID','Category'])\n",
    "print(\"Total Dataframe Train rows:\", len(train_data_merged))\n",
    "print(\"Total Dataframe Test rows:\", len(test_data_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and print difference in label between test and train dataset\n",
    "label_diff = ((train_data_merged['Category'].value_counts(normalize=True) - test_data_merged['Category'].value_counts(normalize=True)) *100).iloc[1]\n",
    "print(f\"Label Distribution relative Difference between Train- and Testset:\\n\",\"±\",np.round(np.abs(label_diff),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into train features (X_crossval) and target (y_crossval)\n",
    "X_crossval = train_data_merged.drop('Category', axis=1)\n",
    "y_crossval = train_data_merged['Category']\n",
    "\n",
    "# Perform Stratified Cross-Validation with fold numbers\n",
    "n_splits = 5  # Number of folds\n",
    "stratified_kf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "# Create a new DataFrame to store the fold number\n",
    "train_data_merged['fold'] = -1  # Initialize with -1\n",
    "label_distributions = []\n",
    "fold_number = 0  # Initialize fold number\n",
    "\n",
    "for _, test_index in stratified_kf.split(X_crossval, y_crossval):\n",
    "    y_test = y_crossval.iloc[test_index]\n",
    "\n",
    "    # Update the fold number for the corresponding rows in the new DataFrame\n",
    "    train_data_merged.loc[test_index, 'fold'] = fold_number\n",
    "    label_distribution_fold = y_test.value_counts(normalize=True).to_dict()\n",
    "    label_distributions.append(label_distribution_fold)\n",
    "\n",
    "    fold_number += 1  # Increment the fold number\n",
    "    print(f\"Total Dataframe Fold {fold_number} rows:\", len(test_index))\n",
    "    \n",
    "    # Calculate and print the relative label differences\n",
    "for i in range(n_splits):\n",
    "    for j in range(i + 1, n_splits):\n",
    "        label_diff = sum(abs(label_distributions[i][k] - label_distributions[j][k]) for k in label_distributions[i])\n",
    "        print(f\"Label Distribution relative Difference between Fold {i} vs. Fold {j}:\\n\",\"±\",np.round(label_diff,3),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and test data to CSV files\n",
    "train_data_merged.to_csv(r'../data/train_data_dirty_not_imputed.csv', index=False)\n",
    "test_data_merged.to_csv(r'../data/test_data_dirty_not_imputed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End Data Partitioning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro5d-classification-prolactinoma-FBKpBkq7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
