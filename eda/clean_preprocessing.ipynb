{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook is used to clean and combine all datasources into a coherent dataset. \n",
    "\n",
    "We have three different data groups:\n",
    "* Label & Patient Data\n",
    "* Lab Data\n",
    "* MRI Data\n",
    "\n",
    "All of these have to be cleaned, selected and combined into one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Selection Label & Patient-data\n",
    "First we will clean the data for our labels and patients. This includes the basic cleaning and data type matching as well as looking at anomalies and define the output format. We will use the prepared 'no duplicate PID' Sheet with Labels from KSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Clean and Preprocessing patients-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = pd.read_excel(r'../raw_data/Hypophysenpatienten.xlsx',sheet_name='no duplicate PID')\n",
    "df_patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Cleaning, Column Selection, Anomaly Correction and Format definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Selection\n",
    "First we select only the columns which have value to our model or our analysis. Some columns are already renamed to make their content more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define needed columns\n",
    "column_list = ['PID','Fall Nr.',\"Datum/Zeit\",\"Arbeitsplatz.Kürzel\",'Grösse',\n",
    "       'Ausfälle prä', 'Qualität', 'ED','OP Datum',\n",
    "       'Diagnose', 'Kategorie', 'Patient Alter',\n",
    "       'Prolaktin',\"IGF1\", 'Cortisol','fT4','weiteres Labor']\n",
    "df_patients = df_patients[column_list]\n",
    "# rename columns\n",
    "df_patients= df_patients.rename(columns={\"Fall Nr.\": \"Case_ID\",\"PID\": \"Patient_ID\",\n",
    "                       \"Datum/Zeit\": \"Date_Case\",\"ED\": \"Entry_date\", \"OP Datum\": \"Operation_date\",\n",
    "                       \"Arbeitsplatz.Kürzel\":\"ID_MRI_Machine\",\"Grösse\": \"Adenoma_size\",\"Qualität\": \"Label_Quality\",\n",
    "                       \"Patient Alter\":\"Patient_age\",\"Kategorie\":\"Category\",\"Diagnose\":\"Diagnosis\",\n",
    "                       \"Prolaktin\":\"Prolactin\",\"weiteres Labor\":\"Lab_additional\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Anomalies and correct them\n",
    "There are some Anomalies mostly in the datetime columns (eg. Operation date before Entry Date). These are corrected or were corrected by the KSA after feedback from us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check KSA\n",
    "# not parseable correct values corrected\n",
    "# df_patients.loc[3,'Entry_date'] = datetime.datetime(2006,1,1,0,0,0,0)\n",
    "# df_patients.loc[12,'Entry_date'] = datetime.datetime(2008,1,1,0,0,0,0)\n",
    "\n",
    "#TODO: check KSA\n",
    "# correct a value which is not datetime parseable\n",
    "# df_patients.loc[df_patients['Operation_date'] == '2006, 2009', 'Operation_date'] = datetime.datetime(2006,1,1,0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: anomaly? check KSA\n",
    "# rows where Entry Date is after Operationdate?\n",
    "df_patients[df_patients['Operation_date'] < df_patients['Entry_date']][['Entry_date','Operation_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Definition\n",
    "Now we check the column data-types and parse them into their resprective type if not already correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datetime values\n",
    "df_patients[\"Date_Case\"] = pd.to_datetime(df_patients[\"Date_Case\"])\n",
    "df_patients[\"Entry_date\"] = pd.to_datetime(df_patients[\"Entry_date\"])\n",
    "df_patients[\"Operation_date\"] = pd.to_datetime(df_patients[\"Operation_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set category data type in pandas, check datatypes\n",
    "df_patients['ID_MRI_Machine'] = df_patients['ID_MRI_Machine'].astype('category')\n",
    "df_patients['Adenoma_size'] = df_patients['Adenoma_size'].astype('category')\n",
    "df_patients['Label_Quality'] = df_patients['Label_Quality'].astype('category')\n",
    "df_patients['Diagnosis'] = df_patients['Diagnosis'].astype('category')\n",
    "df_patients['Category'] = df_patients['Category'].astype('category')\n",
    "df_patients.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Duplicates\n",
    "Check if a patient is duplicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient ID Duplicate Check\n",
    "assert len(df_patients[df_patients[\"Patient_ID\"].duplicated()]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace some Spelling mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace and correct wrong namings from labelers\n",
    "df_patients[\"Ausfälle prä\"]= df_patients[\"Ausfälle prä\"].str.replace(\"intak\",\"intakt\")\n",
    "df_patients[\"Ausfälle prä\"]= df_patients[\"Ausfälle prä\"].str.replace(\"intaktt\",\"intakt\")\n",
    "df_patients[\"Ausfälle prä\"]= df_patients[\"Ausfälle prä\"].str.replace(\"goando\",\"gonado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encode Categorical Values\n",
    "\n",
    "To use and analyse the categorical data we need to one-hot encode them. This is done by splitting the comma separated strings into single strings and then create a one-hot-encoded column of each individual value. This column is then added to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'Ausfälle prä' column into separate strings\n",
    "df_patients['Ausfälle prä'] = df_patients['Ausfälle prä'].str.split(', ')\n",
    "# Create a set to store all unique disfunctions\n",
    "unique_disfunctions = set()\n",
    "\n",
    "# Iterate over the 'Ausfälle prä' column to gather unique disfunctions\n",
    "for value in df_patients['Ausfälle prä']:\n",
    "    if isinstance(value, list):\n",
    "        unique_disfunctions.update(value)\n",
    "    elif isinstance(value, str):\n",
    "        unique_disfunctions.add(value)\n",
    "\n",
    "# Iterate over the unique disfunctions and create one-hot encoded columns\n",
    "for disfunction in unique_disfunctions:\n",
    "    df_patients[\"Pre_OP_hormone_\"+ disfunction] = df_patients['Ausfälle prä'].apply(lambda x: 1 if (isinstance(x, list) and disfunction in x) or (x == disfunction) else 0)\n",
    "# drop the original 'Ausfälle prä' column\n",
    "df_patients = df_patients.drop('Ausfälle prä', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove All NA and not needed Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all labels which are not prolaktion or non-prolaktinom\n",
    "df_patients = df_patients[df_patients['Category'].isin(['non-prolaktinom','prolaktinom'])]\n",
    "assert len(df_patients['Category'].unique()) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.to_csv(r'../raw_data/label_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End Clean and Preprocessing patient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Selection MRI-data\n",
    "\n",
    "Now we will clean all MRI's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Clean and Preprocessing mri data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Selection\n",
    "Only select the interesting columns for the mri's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_mri = ['PID','Fall Nr.',\"Datum/Zeit\",\"Arbeitsplatz.Kürzel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri = pd.read_excel(r'../raw_data/Hypophysenpatienten.xlsx',sheet_name='w duplicates')\n",
    "# select and rename columns\n",
    "df_mri = df_mri[column_list_mri]\n",
    "df_mri= df_mri.rename(columns={\"Fall Nr.\": \"Case_ID\",\"PID\": \"Patient_ID\",\n",
    "                       \"Datum/Zeit\": \"Date_Case\",\"Arbeitsplatz.Kürzel\":\"ID_MRI_Machine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri['Case_ID'] = df_mri['Case_ID'].replace('-','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri['Case_ID']=df_mri['Case_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove same Day MRI and take only newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri_clean = df_mri.groupby([\"Patient_ID\",\"Case_ID\"])[[\"Date_Case\",'ID_MRI_Machine']].max().reset_index()\n",
    "\n",
    "# if there are multiple\n",
    "n_cases = len(df_mri_clean)\n",
    "df_mri_clean = df_mri_clean.groupby([\"Patient_ID\",\"Case_ID\"])[[\"Date_Case\",'ID_MRI_Machine']].max().reset_index()\n",
    "print(f\"{n_cases-len(df_mri_clean)} Cases were deleted, because they were same-day duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri_clean.to_csv(r'../raw_data/mri_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End Clean and Preprocessing mri data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Selection Lab-data\n",
    "\n",
    "Now the lab data from the explicit KSA export will be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Clean and Preprocessing lab-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data = pd.read_excel(\"../raw_data/extract_pit.xlsx\",\n",
    "                         usecols=['PATIENT_NR','FALL_NR','Analyse-ID','Resultat','Datum_Resultat']).rename(\n",
    "                             columns={\"PATIENT_NR\":\"Patient_ID\",\"FALL_NR\":\"Case_ID\",\"Analyse-ID\":\"Lab_ID\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and select Lab's\n",
    "There is a multitude of labs in the export. We do not need all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove not needed labs\n",
    "lab_data= lab_data[~lab_data['Lab_ID'].isin(['ABTEST','TBILHB'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename labs which are integer based with a string name\n",
    "lab_data['Lab_ID'] = lab_data['Lab_ID'].replace({20396:'IGF1',24382:'PROL',24384:'PROL',24383:'PROL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data['Case_ID']= lab_data['Case_ID'].replace('#','',regex=True)\n",
    "lab_data['Case_ID']=lab_data['Case_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace export anomalies \n",
    "ids = {'Ã¼': 'ü', 'Ã¤': 'ä', \"Ã„\":\"Ä\",\"√§\":\"ä\"}\n",
    "\n",
    "for column in lab_data.columns[lab_data.columns.isin([\"Case_ID\",\"Patient_ID\",\"Datum_Resultat\",\"Auftragsdatum\"]) == False]:\n",
    "    for old, new in ids.items():\n",
    "        lab_data[column] = lab_data[column].str.replace(old, new, regex=False)\n",
    "\n",
    "# clean the greather and less than characters with regex\n",
    "clean_result = lambda result: re.sub(r'(?<!\\d)\\.', '', re.sub(r'[^\\d.]', '', str(result))) #clean < zahl / > zahl / 1 A zahl\n",
    "lab_data[\"Resultat\"] = lab_data[\"Resultat\"].apply(clean_result) \n",
    "# remove empty results\n",
    "lab_data = lab_data[lab_data[\"Resultat\"] != \"\"]\n",
    "lab_data[\"Resultat\"] = lab_data[\"Resultat\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the datetime was correctly fixed\n",
    "assert lab_data[\"Datum_Resultat\"].min() > pd.to_datetime(\"1995-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of results of same date\n",
    "lab_data = lab_data.groupby([\"Patient_ID\",\"Lab_ID\",\"Datum_Resultat\"])[\"Resultat\"].agg(['mean']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Cases with Patient Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data = pd.merge(lab_data,df_mri_clean,on=\"Patient_ID\",how = \"right\")\n",
    "lab_data = lab_data[lab_data[\"Date_Case\"] >= lab_data[\"Datum_Resultat\"]].drop(columns=\"Date_Case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute newest date for each patient and analysis\n",
    "max_dates = lab_data.groupby(['Patient_ID', \"Lab_ID\",\"Case_ID\"])['Datum_Resultat'].max().reset_index()\n",
    "# Merge with the original DataFrame to filter rows with minimum dates\n",
    "lab_data = pd.merge(lab_data, max_dates, on=['Patient_ID', 'Lab_ID', 'Datum_Resultat',\"Case_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any duplicate Values\n",
    "assert len(lab_data.loc[:,[\"Case_ID\",\"Lab_ID\"]].drop_duplicates()) == len(lab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe wide\n",
    "lab_data = lab_data.pivot(index=[\"Patient_ID\",\"Case_ID\"],values = ['mean'], columns = ['Lab_ID'])\n",
    "lab_data.columns = lab_data.columns.droplevel()\n",
    "lab_data = lab_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LabData from label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab = pd.read_csv(r'../raw_data/label_data.csv').rename(columns={'Cortisol':'COR60','fT4':'FT4','Prolactin':'PROL'})[['Patient_ID','Case_ID','COR60','FT4','PROL','IGF1','Lab_additional']]\n",
    "df_additional_lab.columns\n",
    "df_additional_lab = df_additional_lab.dropna(subset=['PROL','IGF1','COR60','FT4',]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['Lab_additional'] =df_additional_lab['Lab_additional'].fillna('')\n",
    "for i in ['Test', 'LH','FSH']:\n",
    "    df_additional_lab[i] = ''\n",
    "    indices = df_additional_lab[df_additional_lab['Lab_additional'].str.contains(i)].index\n",
    "    df_additional_lab.loc[indices,i]  = df_additional_lab.iloc[indices]['Lab_additional']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab= df_additional_lab.drop(columns=['Lab_additional'])\n",
    "df_additional_lab= df_additional_lab.rename(columns={'Test':'TEST'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Rows   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Tristan fragen\n",
    "df_additional_lab[df_additional_lab['Patient_ID'] ==300071920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab= df_additional_lab.drop(df_additional_lab[df_additional_lab['Patient_ID'] ==300071920].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testosteron Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r' nmol/l','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'nmol/l','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'nmol','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'Testo','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'Test','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r',','.',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab.loc[df_additional_lab['TEST'] == '', 'TEST'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['TEST']= df_additional_lab['TEST'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LH Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab.loc[df_additional_lab['LH'] == '', 'LH'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FSH Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['FSH'] = df_additional_lab['FSH'].replace(r'FSH','',regex=True)\n",
    "df_additional_lab['FSH'] = df_additional_lab['FSH'].replace(r'U/L','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab.loc[df_additional_lab['FSH'] == '', 'FSH'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cortisol Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['COR60'] = df_additional_lab['COR60'].replace(r' nmol/l','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FT4 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['FT4'] = df_additional_lab['FT4'].replace(r' pmol/l','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prolaktin Cleaning and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab[\"PROL\"]= df_additional_lab[\"PROL\"].str.replace(\"ug/L\",\"ug/l\")\n",
    "df_additional_lab[\"PROL\"]= df_additional_lab[\"PROL\"].str.replace(\"mu/L\",\"mU/l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices which need to be converted\n",
    "indices_to_divide = df_additional_lab.loc[df_additional_lab[\"PROL\"].str.contains('mU/l'),'PROL'].index \n",
    "# remove units and strings\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].str.rstrip(r'mU/l')\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].str.rstrip(r'ug/l')\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].str.rstrip(r'ug/L')\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].astype(float)\n",
    "# mU/l -> ug/l (mU/l * 0.048)\n",
    "df_additional_lab.loc[indices_to_divide,'PROL'] = df_additional_lab.loc[indices_to_divide,'PROL'] * 0.048 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGF1 Cleaning and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab[\"IGF1\"]= df_additional_lab[\"IGF1\"].str.replace(\"ug/L\",\"ug/l\")\n",
    "df_additional_lab[\"IGF1\"]= df_additional_lab[\"IGF1\"].str.replace(\",\",\".\")\n",
    "\n",
    "# get indices which need to be converted\n",
    "indices_to_divide = df_additional_lab.loc[df_additional_lab[\"IGF1\"].str.contains('ng/ml'),'IGF1'].index \n",
    "# remove units and strings\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].str.rstrip(r'ng/ml')\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].str.rstrip(r'nmol')\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].str.rstrip(r'nmol/l')\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].astype(float)\n",
    "# ng/ml -> nmol/l (ng/ml * 0.13)\n",
    "df_additional_lab.loc[indices_to_divide,'IGF1'] = df_additional_lab.loc[indices_to_divide,'IGF1'] * 0.13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine additional lab and lab data\n",
    "lab_data = lab_data.set_index(['Patient_ID','Case_ID']).combine_first(df_additional_lab.set_index(['Patient_ID','Case_ID'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spar = round(lab_data[['COR60', 'FSH','LH', 'FT4', 'IGF1', 'LH', 'PROL','TEST']].isna().mean().mean(),3)\n",
    "print(f\"Sparsity of labordata: {spar} % (nur von Fällen mit Laborwerten)\")\n",
    "print(f\"Von {len(df_mri_clean)-len(lab_data)} Fällen gibt es keine Laborwerte.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data.to_csv(r'../raw_data/lab_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End Clean and Preprocessing labor data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only newest mri\n",
    "# df_mri_clean = df_mri.sort_values(['Patient_ID','Date_Case'],ascending=False).drop_duplicates('Patient_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.merge(df_mri_clean,lab_data,left_on=['Patient_ID','Case_ID'],right_on=['Patient_ID','Case_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged = pd.merge(df_temp,df_patients[['Patient_ID', 'Entry_date', 'Operation_date', 'Adenoma_size',\n",
    "       'Diagnosis', 'Category', 'Patient_age','Pre_OP_hormone_cortico',\n",
    "       'Pre_OP_hormone_gonado', 'Pre_OP_hormone_somato',\n",
    "       'Pre_OP_hormone_thyreo', 'Pre_OP_hormone_hyperprolaktin',\n",
    "       'Pre_OP_hormone_keine', 'Pre_OP_hormone_intakt', 'Label_Quality']],how='inner',left_on=['Patient_ID'],right_on=['Patient_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged = full_merged.sort_values('Patient_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert full_merged.duplicated(subset=['Patient_ID','Case_ID']).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged.to_csv(r'../raw_data/data_full_merge.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgroLuege--zjmSdF3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
