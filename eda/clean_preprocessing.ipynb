{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook is used to clean and combine all datasources into a coherent dataset. \n",
    "\n",
    "We have three different data groups:\n",
    "* Label & Patient Data\n",
    "* Lab Data\n",
    "* MRI Data\n",
    "\n",
    "All of these have to be cleaned, selected and combined into one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Selection Label & Patient-data\n",
    "First we will clean the data for our labels and patients. This includes the basic cleaning and data type matching as well as looking at anomalies and define the output format. We will use the prepared 'no duplicate PID' Sheet with Labels from KSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Clean and Preprocessing patients-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = pd.read_excel(r'../raw_data/Hypophysenpatienten.xlsx',sheet_name='no duplicate PID')\n",
    "df_patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Cleaning, Column Selection, Anomaly Correction and Format definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Selection\n",
    "First we select only the columns which have value to our model or our analysis. Some columns are already renamed to make their content more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define needed columns\n",
    "column_list = ['PID','Fall Nr.',\"Datum/Zeit\",\"Arbeitsplatz.Kürzel\",'Grösse',\n",
    "       'Ausfälle prä', 'Qualität', 'ED','OP Datum',\n",
    "       'Diagnose', 'Kategorie', 'Patient Alter',\n",
    "       'Prolaktin',\"IGF1\", 'Cortisol','fT4','weiteres Labor','Gender']\n",
    "df_patients = df_patients[column_list]\n",
    "# rename columns\n",
    "df_patients= df_patients.rename(columns={\"Fall Nr.\": \"Case_ID\",\"PID\": \"Patient_ID\",\n",
    "                       \"Datum/Zeit\": \"Date_Case\",\"ED\": \"Diagnosis_Date\", \"OP Datum\": \"Operation_date\",\n",
    "                       \"Arbeitsplatz.Kürzel\":\"ID_MRI_Machine\",\"Grösse\": \"Adenoma_size\",\"Qualität\": \"Label_Quality\",\n",
    "                       \"Patient Alter\":\"Patient_age\",\"Kategorie\":\"Category\",\"Diagnose\":\"Diagnosis\",\n",
    "                       \"Prolaktin\":\"Prolactin\",\"weiteres Labor\":\"Lab_additional\", 'Gender':\"Patient_gender\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Anomalies and correct them\n",
    "There are some Anomalies mostly in the datetime columns (eg. Operation date before Entry Date). These are corrected or were corrected by the KSA after feedback from us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows where Entry Date is after Operationdate?\n",
    "assert len(df_patients[df_patients['Operation_date'] < df_patients['Diagnosis_Date']][['Diagnosis_Date','Operation_date']]) ==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Definition\n",
    "Now we check the column data-types and parse them into their resprective type if not already correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datetime values\n",
    "df_patients[\"Date_Case\"] = pd.to_datetime(df_patients[\"Date_Case\"])\n",
    "df_patients[\"Diagnosis_Date\"] = pd.to_datetime(df_patients[\"Diagnosis_Date\"])\n",
    "df_patients[\"Operation_date\"] = pd.to_datetime(df_patients[\"Operation_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set category data type in pandas, check datatypes\n",
    "df_patients['ID_MRI_Machine'] = df_patients['ID_MRI_Machine'].astype('category')\n",
    "df_patients['Adenoma_size'] = df_patients['Adenoma_size'].astype('category')\n",
    "df_patients['Diagnosis'] = df_patients['Diagnosis'].astype('category')\n",
    "df_patients['Category'] = df_patients['Category'].astype('category')\n",
    "df_patients['Patient_gender'] = df_patients['Patient_gender'].astype('category')\n",
    "df_patients.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Duplicates\n",
    "Check if a patient is duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient ID Duplicate Check\n",
    "assert len(df_patients[df_patients[\"Patient_ID\"].duplicated()]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encode Categorical Values\n",
    "\n",
    "To use and analyse the categorical data we need to one-hot encode them. This is done by splitting the comma separated strings into single strings and then create a one-hot-encoded column of each individual value. This column is then added to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients[\"Ausfälle prä\"]= df_patients[\"Ausfälle prä\"].str.replace(' ', '')\n",
    "df_patients[\"Ausfälle prä\"]= df_patients[\"Ausfälle prä\"].str.lower()\n",
    "# Split the 'Ausfälle prä' column into separate strings\n",
    "df_patients['Ausfälle prä'] = df_patients['Ausfälle prä'].str.split(',')\n",
    "\n",
    "# Create a set to store all unique disfunctions\n",
    "unique_disfunctions = set()\n",
    "\n",
    "# Iterate over the 'Ausfälle prä' column to gather unique disfunctions\n",
    "for value in df_patients['Ausfälle prä']:\n",
    "    if isinstance(value, list):\n",
    "        unique_disfunctions.update(value)\n",
    "    elif isinstance(value, str):\n",
    "        unique_disfunctions.add(value)\n",
    "\n",
    "# Iterate over the unique disfunctions and create one-hot encoded columns\n",
    "for disfunction in unique_disfunctions:\n",
    "    df_patients[\"Pre_OP_hormone_\"+ disfunction] = df_patients['Ausfälle prä'].apply(lambda x: 1 if (isinstance(x, list) and disfunction in x) or (x == disfunction) else 0)\n",
    "# drop the original 'Ausfälle prä' column\n",
    "df_patients = df_patients.drop('Ausfälle prä', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove All NA and not needed Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all labels which are not prolaktion or non-prolaktinom\n",
    "df_patients = df_patients[df_patients['Category'].isin(['non-prolaktinom','prolaktinom'])]\n",
    "assert len(df_patients['Category'].unique()) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.to_csv(r'../raw_data/label_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End Clean and Preprocessing patient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Selection MRI-data\n",
    "\n",
    "Now we will clean all MRI's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Clean and Preprocessing mri data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Selection\n",
    "Only select the interesting columns for the mri's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read MRI Data\n",
    "df_mri = pd.read_excel(r'../raw_data/Hypophysenpatienten.xlsx',sheet_name='w duplicates')\n",
    "# select and rename columns\n",
    "column_list_mri = ['PID','Fall Nr.',\"Datum/Zeit\",\"Arbeitsplatz.Kürzel\",'%ID']\n",
    "df_mri = df_mri[column_list_mri]\n",
    "df_mri= df_mri.rename(columns={\"Fall Nr.\": \"Case_ID\",\"PID\": \"Patient_ID\",\n",
    "                       \"Datum/Zeit\": \"Date_Case\",\"Arbeitsplatz.Kürzel\":\"ID_MRI_Machine\",'%ID':\"MRI_Case_ID\",})\n",
    "\n",
    "# replace chars and make a senseful caseid\n",
    "df_mri['Case_ID'] = df_mri['Case_ID'].replace('-', '', regex=True)\n",
    "df_mri['Case_ID'] = df_mri['Case_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge patient data to mri\n",
    "df_mri_merge = df_mri.merge(df_patients[['Patient_ID','Operation_date','Diagnosis_Date']], how='left', on=\"Patient_ID\")\n",
    "# create op and non op patient mri subsets\n",
    "df_mri_op = df_mri_merge[~df_mri_merge['Operation_date'].isna()]\n",
    "df_mri_nonop = df_mri_merge[df_mri_merge['Operation_date'].isna()]\n",
    "\n",
    "# for patients with an operation get newest MRI, which is not newer than the operation date and not older than the diagnosis date \n",
    "df_mri_op = df_mri_op[(df_mri_op['Date_Case'] <= df_mri_op['Operation_date']) &  (df_mri_op['Date_Case'] >= df_mri_op['Diagnosis_Date'])].groupby([\"Patient_ID\",\"Case_ID\"]).min().reset_index()\n",
    "# for patients without an operation get oldest MRI, which is not older than the diagnosis date\n",
    "df_mri_nonop = df_mri_nonop[(df_mri_nonop['Date_Case'] >= df_mri_nonop['Diagnosis_Date'])].groupby([\"Patient_ID\",\"Case_ID\"]).min().reset_index()\n",
    "# concat subsets\n",
    "df_mri = pd.concat([df_mri_op,df_mri_nonop]).reset_index(drop=True)\n",
    "# remove same day multiples\n",
    "n_cases = len(df_mri)\n",
    "df_mri_clean = df_mri.groupby([\"Patient_ID\",\"Case_ID\"])[[\"Date_Case\",'ID_MRI_Machine',\"MRI_Case_ID\"]].min().reset_index()\n",
    "\n",
    "# if there are multiple\n",
    "print(f\"{n_cases-len(df_mri_clean)} Cases were deleted, because they were same-day duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no MRI-files for these Cases. [8152562, 7661718, 7371681]\n",
    "no_mri_cases = [41040108, 40632245,41040108,40367289, 40089238]\n",
    "df_mri_clean = df_mri_clean[~df_mri_clean[\"Case_ID\"].isin(no_mri_cases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri_clean = df_mri_clean.sort_values('Patient_ID')\n",
    "df_mri_clean.to_csv(r'../raw_data/mri_data_all.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End Clean and Preprocessing mri data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Selection Lab-data\n",
    "\n",
    "Now the lab data from the explicit KSA export will be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Clean and Preprocessing lab-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data = pd.read_excel(\"../raw_data/extract_pit.xlsx\",\n",
    "                         usecols=['PATIENT_NR','FALL_NR','Analyse-ID','Resultat','Datum_Resultat','Auftragsdatum']).rename(\n",
    "                             columns={\"PATIENT_NR\":\"Patient_ID\",\"FALL_NR\":\"Case_ID\",\"Analyse-ID\":\"Lab_ID\",})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and select Lab's\n",
    "There is a multitude of labs in the export. We do not need all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove not needed labs\n",
    "lab_data = lab_data[~lab_data['Lab_ID'].isin(['ABTEST','TBILHB'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename labs which are integer based with a string name\n",
    "lab_data['Lab_ID'] = lab_data['Lab_ID'].replace({20396:'IGF1',24382:'PROL',24384:'PROL',24383:'PROL',\n",
    "                                                 'COR30':'COR','COR60':'COR',\n",
    "                                                 'CORL0':'COR','CORL30':'COR',\n",
    "                                                 'COR0':'COR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data['Auftragsdatum'] = pd.to_datetime(lab_data['Auftragsdatum'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace some not used characters in the case ids\n",
    "lab_data['Case_ID'] = lab_data['Case_ID'].replace('#','',regex=True)\n",
    "lab_data['Case_ID'] = lab_data['Case_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean result column\n",
    "lab_data['Resultat'] = lab_data['Resultat'].replace(',','.',regex=True)\n",
    "lab_data['Resultat'] = lab_data['Resultat'].replace('>','',regex=True)\n",
    "lab_data['Resultat'] = lab_data['Resultat'].replace('<','',regex=True)\n",
    "lab_data['Resultat'] = lab_data['Resultat'].replace('¬†','',regex=True)\n",
    "lab_data['Resultat'] = lab_data['Resultat'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace export anomalies \n",
    "ids = {'Ã¼': 'ü', 'Ã¤': 'ä', \"Ã„\":\"Ä\",\"√§\":\"ä\"}\n",
    "\n",
    "for column in lab_data.columns[lab_data.columns.isin([\"Case_ID\",\"Patient_ID\",\"Datum_Resultat\",\"Auftragsdatum\"]) == False]:\n",
    "    for old, new in ids.items():\n",
    "        lab_data[column] = lab_data[column].replace(old, new, regex=False)\n",
    "\n",
    "# clean the greather and less than characters with regex\n",
    "clean_result = lambda result: re.sub(r'(?<!\\d)\\.', '', re.sub(r'[^\\d.]', '', str(result))) #clean < zahl / > zahl / 1 A zahl\n",
    "lab_data[\"Resultat\"] = lab_data[\"Resultat\"].apply(clean_result) \n",
    "# remove empty results\n",
    "lab_data = lab_data[lab_data[\"Resultat\"] != \"\"]\n",
    "lab_data[\"Resultat\"] = lab_data[\"Resultat\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the datetime was correctly fixed\n",
    "assert lab_data[\"Datum_Resultat\"].min() > pd.to_datetime(\"1995-01-01\")\n",
    "assert lab_data[\"Auftragsdatum\"].min() > pd.to_datetime(\"1995-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of results of same date\n",
    "lab_data = lab_data.groupby([\"Patient_ID\",'Case_ID',\"Lab_ID\",\"Auftragsdatum\"])[\"Resultat\"].agg(['mean']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe wide\n",
    "lab_data = lab_data.pivot(index=[\"Patient_ID\",\"Case_ID\",\"Auftragsdatum\"], values = ['mean'], columns = ['Lab_ID'])\n",
    "lab_data.columns = lab_data.columns.droplevel()\n",
    "lab_data = lab_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LabData from label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab = pd.read_csv(r'../raw_data/label_data.csv').rename(columns={'Cortisol':'COR','fT4':'FT4','Prolactin':'PROL'})[['Patient_ID','Case_ID','COR','FT4','PROL','IGF1','Lab_additional']]\n",
    "df_additional_lab = df_additional_lab.dropna(subset=['PROL','IGF1','COR','FT4','Lab_additional'], how='all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['Lab_additional'] = df_additional_lab['Lab_additional'].fillna('')\n",
    "for i in ['Test', 'LH','FSH']:\n",
    "    df_additional_lab[i] = ''\n",
    "    indices = df_additional_lab[df_additional_lab['Lab_additional'].str.contains(i)].index\n",
    "    df_additional_lab.loc[indices,i] = df_additional_lab.iloc[indices]['Lab_additional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab = df_additional_lab.drop(columns=['Lab_additional'])\n",
    "df_additional_lab = df_additional_lab.rename(columns={'Test':'TEST'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testosteron Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r' nmol/l','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'nmol/l','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'nmol','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'Testo','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r'Test','',regex=True)\n",
    "df_additional_lab['TEST'] = df_additional_lab['TEST'].replace(r',','.',regex=True)\n",
    "df_additional_lab.loc[df_additional_lab['TEST'] == '', 'TEST'] = np.nan\n",
    "df_additional_lab['TEST']= df_additional_lab['TEST'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LH Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab.loc[df_additional_lab['LH'] == '', 'LH'] = np.nan\n",
    "df_additional_lab['LH'] = df_additional_lab['LH'].replace(r'FSH \\d*U\\/L,','',regex=True)\n",
    "df_additional_lab['LH'] = df_additional_lab['LH'].replace(r'LH','',regex=True)\n",
    "df_additional_lab['LH'] = df_additional_lab['LH'].replace(r'U/L','',regex=True)\n",
    "df_additional_lab['LH']= df_additional_lab['LH'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FSH Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['FSH'] = df_additional_lab['FSH'].replace(r'FSH','',regex=True)\n",
    "df_additional_lab['FSH'] = df_additional_lab['FSH'].replace(r'U/L','',regex=True)\n",
    "df_additional_lab['FSH'] = df_additional_lab['FSH'].replace(r', LH \\d*','',regex=True)\n",
    "\n",
    "df_additional_lab.loc[df_additional_lab['FSH'] == '', 'FSH'] = np.nan\n",
    "df_additional_lab['FSH']= df_additional_lab['FSH'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cortisol Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['COR'] = df_additional_lab['COR'].replace(r' nmol/l','',regex=True)\n",
    "df_additional_lab['COR']= df_additional_lab['COR'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FT4 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab['FT4'] = df_additional_lab['FT4'].replace(r' pmol/l','',regex=True)\n",
    "df_additional_lab['FT4']= df_additional_lab['FT4'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prolaktin Cleaning and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lab[\"PROL\"]= df_additional_lab[\"PROL\"].str.replace(\"ug/L\",\"ug/l\")\n",
    "df_additional_lab[\"PROL\"]= df_additional_lab[\"PROL\"].str.replace(\"mu/L\",\"mU/l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices which need to be converted\n",
    "# indices_to_divide = df_additional_lab.loc[df_additional_lab[\"PROL\"].str.contains('mU/l'),'PROL'].index \n",
    "indices_to_divide = df_additional_lab[~df_additional_lab[\"PROL\"].isna() & df_additional_lab['PROL'].str.contains('mU/l')].index \n",
    "# remove units and strings\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].str.rstrip(r'mU/l')\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].str.rstrip(r'ug/l')\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].str.rstrip(r'ug/L')\n",
    "df_additional_lab['PROL'] = df_additional_lab['PROL'].astype(float)\n",
    "# mU/l -> ug/l (mU/l * 0.048)\n",
    "df_additional_lab.loc[indices_to_divide,'PROL'] = df_additional_lab.loc[indices_to_divide,'PROL'] * 0.048 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGF1 Cleaning and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_additional_lab[\"IGF1\"]= df_additional_lab[\"IGF1\"].str.replace(\"ug/L\",\"ug/l\")\n",
    "df_additional_lab[\"IGF1\"]= df_additional_lab[\"IGF1\"].str.replace(\"ug/l\",\"\")\n",
    "df_additional_lab[\"IGF1\"]= df_additional_lab[\"IGF1\"].str.replace(\",\",\".\")\n",
    "\n",
    "# get indices which need to be converted\n",
    "# indices_to_divide = df_additional_lab.loc[df_additional_lab[\"IGF1\"].str.contains('ng/ml'),'IGF1'].index \n",
    "indices_to_divide = df_additional_lab[~df_additional_lab[\"IGF1\"].isna() & df_additional_lab['IGF1'].str.contains('ng/ml')].index\n",
    "# remove units and strings\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].str.rstrip(r'ng/ml')\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].str.rstrip(r'nmol')\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].str.rstrip(r'nmol/l')\n",
    "df_additional_lab['IGF1'] = df_additional_lab['IGF1'].astype(float)\n",
    "# ng/ml -> nmol/l (ng/ml * 0.13)\n",
    "df_additional_lab.loc[indices_to_divide,'IGF1'] = df_additional_lab.loc[indices_to_divide,'IGF1'] * 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine additional lab and lab data by combining the first occurence\n",
    "lab_data = lab_data.set_index(['Patient_ID','Case_ID']).combine_first(df_additional_lab.set_index(['Patient_ID','Case_ID'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge patient data to labdata\n",
    "lab_data_merge = lab_data.merge(df_patients[['Patient_ID','Operation_date','Diagnosis_Date']], how='left', on=\"Patient_ID\")\n",
    "\n",
    "# create op and non op patient labdata subsets\n",
    "lab_data_op = lab_data_merge[~lab_data_merge['Operation_date'].isna()]\n",
    "lab_data_nonop = lab_data_merge[lab_data_merge['Operation_date'].isna()]\n",
    "# for patients with an operation get newest labdata, which is not newer than the operation date (including an offset of 2 months, after op diagnostics is later) and not older than the diagnosis date \n",
    "lab_data_op = lab_data_op[(lab_data_op['Auftragsdatum'] <= lab_data_op['Operation_date'] + pd.DateOffset(weeks=1)) & (lab_data_op['Auftragsdatum'] >= lab_data_op['Diagnosis_Date'])].groupby([\"Patient_ID\",\"Case_ID\"]).min().reset_index()\n",
    "# for patients without an operation get oldest labdata, which is not older than the diagnosis date\n",
    "lab_data_nonop = lab_data_nonop[(lab_data_nonop['Auftragsdatum'] >= lab_data_nonop['Diagnosis_Date'])].groupby([\"Patient_ID\",\"Case_ID\"]).min().reset_index()\n",
    "\n",
    "\n",
    "# concat subsets\n",
    "lab_data = pd.concat([lab_data_op,lab_data_nonop]).reset_index(drop=True)\n",
    "\n",
    "# add more patient information\n",
    "lab_data = lab_data.merge(df_patients[['Patient_ID','Patient_gender','Patient_age','Date_Case','Adenoma_size',\n",
    "                                       ]+[col for col in df_patients.columns if \"Pre_\" in col]], how='left', on=\"Patient_ID\")\n",
    "# remove same day multiples\n",
    "n_cases = len(lab_data)\n",
    "lab_data_clean = lab_data.groupby([\"Patient_ID\",\"Case_ID\"])[['Auftragsdatum','COR', 'FSH', 'FT4', 'IGF1',\n",
    "       'LH', 'PROL', 'TEST',]].min().reset_index()\n",
    "\n",
    "# if there are multiple\n",
    "print(f\"{n_cases-len(lab_data_clean)} Cases were deleted, because they were same-day duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spar = round(lab_data_clean[['COR', 'FSH','LH', 'FT4', 'IGF1', 'LH', 'PROL','TEST']].isna().mean().mean(),3)\n",
    "print(f\"Sparsity of labordata: {spar} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data_clean = lab_data_clean.sort_values('Patient_ID')\n",
    "lab_data_clean.to_csv(r'../raw_data/lab_data_all.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End Clean and Preprocessing labor data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mridata where an mri matches to with case and patient if of a lab\n",
    "df_temp = pd.merge(df_mri_clean,lab_data_clean,left_on=['Patient_ID','Case_ID'],right_on=['Patient_ID','Case_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match this data with the patients data\n",
    "full_merged = pd.merge(df_temp,df_patients[['Patient_ID','Category','Patient_gender','Patient_age','Adenoma_size']+\n",
    "                                           list(df_patients.columns[df_patients.columns.str.contains('Pre')])+\n",
    "                                           ['Operation_date', 'Diagnosis_Date']]\n",
    "                                           ,how='inner',left_on=['Patient_ID'],right_on=['Patient_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged = full_merged.sort_values('Patient_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged[\"label\"] = (full_merged[\"Category\"]==\"prolaktinom\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert full_merged.duplicated(subset=['Patient_ID','Case_ID']).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged.to_csv(r'../data/test/test_data_pairs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all non pair data\n",
    "labdata_only_dirty = lab_data[~lab_data['Case_ID'].isin(full_merged['Case_ID'])]\n",
    "mri_only_dirty = df_mri_clean[~df_mri_clean['Case_ID'].isin(full_merged['Case_ID'])]\n",
    "\n",
    "# add nan as fold\n",
    "labdata_only_dirty.to_csv(r'../raw_data/lab_data_only_dirty.csv',index=False)\n",
    "mri_only_dirty.to_csv(r'../raw_data/mri_data_only_dirty.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(df_mri_clean)} MRI's with all constraints applied!\")\n",
    "print(f\"There are {len(lab_data_clean)} Lab's with all constraints applied!\")\n",
    "print(f\"There are {len(full_merged)} Combinations with all constraints applied!\")\n",
    "print(f\"There are {len(labdata_only_dirty)} Lab's which are dirty!\")\n",
    "print(f\"There are {len(mri_only_dirty)} MRI's which are dirty!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro5d-classification-prolactinoma-FBKpBkq7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
