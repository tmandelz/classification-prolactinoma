{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from train_tabular import fit\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "X_train = pd.read_csv(r'../../data/train_data.csv')\n",
    "Y_train = X_train[\"Category\"]\n",
    "\n",
    "X_test = pd.read_csv(r'../../data/test_data.csv')\n",
    "Y_test = X_test[\"Category\"]\n",
    "X_train= X_train.iloc[:,[i for i in range(6,15)]+ [-1]]\n",
    "X_test= X_test.iloc[:,[i for i in range(6,15)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing function\n",
    "X_train.loc[X_train['Patient_gender'] =='male','Patient_gender'] =1\n",
    "X_train.loc[X_train['Patient_gender'] =='female','Patient_gender'] =0\n",
    "X_test.loc[X_test['Patient_gender'] =='male','Patient_gender'] =1\n",
    "X_test.loc[X_test['Patient_gender'] =='female','Patient_gender'] =0\n",
    "\n",
    "# Assuming `data` is your dataset and `columns_to_scale` is a list of column names to scale\n",
    "columns_to_scale = ['COR', 'FSH', 'FT4', 'IGF1', 'LH', 'PROL', 'TEST',]\n",
    "\n",
    "# Create a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # ('cat', OneHotEncoder(drop='first'), ['Patient_gender']),\n",
    "        ('scaler', StandardScaler(), columns_to_scale),\n",
    "    ],\n",
    "    remainder='passthrough'  # This will include the non-specified columns as-is\n",
    ")\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    # You can add more steps to the pipeline if needed\n",
    "])\n",
    "transformed_data = pipeline.fit_transform(X_train)\n",
    "# Get the column names after preprocessing\n",
    "preprocessed_columns = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "# Extract the second part of the column names\n",
    "preprocessed_columns = [col.split('__')[1] if '__' in col else col for col in preprocessed_columns]\n",
    "# Fit and transform your data\n",
    "X_transformed = pd.DataFrame(transformed_data,columns=preprocessed_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandbadd={'max_iter':500}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for fold in range(0,5):\n",
    "    fitted_model_fold = fit(model,X_transformed,Y_train,X_test,Y_test,fold,\"Tab-Data-LogReg-0.9Train\",\"LogReg\",wandb_additional_config=wandbadd)\n",
    "    models.append(fitted_model_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model_fold = fit(model,X_transformed,Y_train,X_test,Y_test,'all',\"Tab-Data-LogReg-All-0.9Train\",\"LogReg\",wandb_additional_config=wandbadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro5d-classification-prolactinoma-tMtLv9PL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
